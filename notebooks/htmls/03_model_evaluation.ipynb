{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db216b97-31b8-4b06-9aad-38e546ea7c87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88213a50-a33c-4fa1-8507-99eebb4f8fac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Model Evaluation for Total Household Deposits\n",
    "\n",
    "This notebook evaluates the final forecast models for each horizon using the hold-out test set (the last 12 months of data). Evaluation is performed using a **backtesting** approach: for each point in the test set, the model is trained on all available data up to time _t - h_ and used to predict the value at time _t_, where _h_ is the forecast horizon.\n",
    "\n",
    "Performance metrics used for assessing robustness and accuracy on unseen data:\n",
    "- **Root Mean Squared Error (RMSE)**\n",
    "- **Mean Absolute Error (MAE)**, and\n",
    "- **Maximum Absolute Error** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae3beee6-0e3d-45ab-b637-7dfb830c69f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sktime.split import temporal_train_test_split\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.performance_metrics.forecasting import mean_absolute_percentage_error, mean_squared_error\n",
    "from sktime.forecasting.residual_booster import ResidualBoostingForecaster\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sktime.forecasting.compose import make_reduction\n",
    "from sktime.forecasting.ets import AutoETS\n",
    "from sktime.forecasting.model_evaluation import evaluate\n",
    "from sktime.forecasting.model_selection import ExpandingWindowSplitter\n",
    "from sktime.forecasting.compose import TransformedTargetForecaster\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Set seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44d47642-4b16-40d1-baec-1c502dcbff61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_features(df, target_col, predictor_cols, lags=[1,3,4, 6,12], rolling_windows=[3,4, 6,12]):\n",
    "    \"\"\"\n",
    "    Creates lag-based and rolling statistical features for both the target and predictor columns.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame with 'date', target, and predictor columns\n",
    "    - target_col (str): Name of the target column\n",
    "    - predictor_cols (list): List of predictor column names\n",
    "    - lags (list): Lags to apply for lag, diff, and pct change features\n",
    "    - rolling_windows (list): Window sizes for rolling statistics (mean, std, min, max)\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with engineered features and datetime features (year, month, quarter)\n",
    "    \"\"\"\n",
    "    # Ensure date is in datetime format\n",
    "    df = df.copy()\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values('date')\n",
    "    df.set_index('date', inplace=True)\n",
    "\n",
    "    new_features = {}\n",
    "\n",
    "    # For each predictor (and target), compute lags, rolling stats, etc.\n",
    "    for col in [target_col] + predictor_cols:\n",
    "        # Lag features\n",
    "        for lag in lags:\n",
    "            new_features[f'{col}_lag{lag}'] = df[col].shift(lag) # lag\n",
    "\n",
    "        # Differences and pct changes\n",
    "        for lag in lags:\n",
    "            new_features[f'{col}_diff{lag}'] = df[col].diff(lag) # difference\n",
    "            if (df[col] != 0).all():\n",
    "                new_features[f'{col}_roc{lag}'] = df[col].pct_change(lag) # rate of change\n",
    "\n",
    "        # Rolling stats\n",
    "        for win in rolling_windows:\n",
    "            new_features[f'{col}_ma{win}'] = df[col].rolling(win).mean()\n",
    "            new_features[f'{col}_std{win}'] = df[col].rolling(win).std()\n",
    "            new_features[f'{col}_min{win}'] = df[col].rolling(win).min()\n",
    "            new_features[f'{col}_max{win}'] = df[col].rolling(win).max()\n",
    "\n",
    "    # Combine original and new features        \n",
    "    df_new = pd.concat([df]+ [pd.DataFrame(new_features, index=df.index)], axis=1)\n",
    "\n",
    "    # Add datetime features\n",
    "    df_new['year'] = df_new.index.year\n",
    "    df_new['month'] = df_new.index.month\n",
    "    df_new['quarter'] = df_new.index.quarter\n",
    "\n",
    "    # Drop rows with missing values caused by shifting/rolling\n",
    "    df_new = df_new.dropna()\n",
    "    df_new.reset_index(inplace=True)\n",
    "\n",
    "    return df_new\n",
    "\n",
    "def prepare_features(df, target, lags, rolling_windows, use_cols):\n",
    "    \"\"\"\n",
    "    Wrapper around create_features to:\n",
    "    - Generate features\n",
    "    - Subset to required columns\n",
    "    - Set proper monthly period index\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame with 'date', target and predictors\n",
    "    - target (str): Target column name\n",
    "    - lags (list): List of lag values\n",
    "    - rolling_windows (list): List of rolling window sizes\n",
    "    - use_cols (list): Final features to retain\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Processed and indexed DataFrame ready for forecasting\n",
    "    \"\"\"\n",
    "\n",
    "    predictor_cols = [x for x in df.columns if x not in ['date', target]]\n",
    "    df = create_features(df, target, predictor_cols, lags=lags, rolling_windows=rolling_windows)\n",
    "    df = df[['date', target] + use_cols].copy()\n",
    "    df = df.set_index('date').asfreq('MS')  # Set frequency to monthly start\n",
    "    df.index = df.index.to_period(\"M\")  # Use PeriodIndex (monthly) as required for sktime\n",
    "    return df\n",
    "\n",
    "def build_forecaster(sp, n_estimators, learning_rate, max_depth, window_length, min_samples_leaf, subsample):\n",
    "    \"\"\"\n",
    "    Builds the combined forecasting model (AutoETS + Gradient Boosting residual corrector).\n",
    "\n",
    "    Parameters:\n",
    "    - sp (int): Seasonal period (e.g. 12 for monthly data with yearly seasonality)\n",
    "    - n_estimators (int): Number of boosting trees\n",
    "    - learning_rate (float): Learning rate for GBT\n",
    "    - max_depth (int): Max tree depth\n",
    "    - window_length (int): Number of past time points used in the residual booster\n",
    "    - min_samples_leaf (int): Minimum samples in leaf node\n",
    "    - subsample (float): Fraction of samples used in boosting\n",
    "     \n",
    "    Returns:\n",
    "    - sktime.forecasting.compose._pipeline.ForecasterPipeline: A composite forecaster object\n",
    "    \"\"\"\n",
    "    base_forecaster = AutoETS(auto=True, sp=sp, n_jobs=-1)\n",
    "\n",
    "    regressor = GradientBoostingRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_leaf = min_samples_leaf, \n",
    "        subsample = subsample, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    residual_model = make_reduction(regressor, window_length=window_length, strategy=\"direct\")\n",
    "    residual_forecaster = TransformedTargetForecaster([\n",
    "        (\"scaler\", MinMaxScaler()),\n",
    "        (\"regressor\", residual_model)\n",
    "    ])\n",
    "\n",
    "    full_forecaster = ResidualBoostingForecaster(base_forecaster, residual_forecaster)\n",
    "    return full_forecaster\n",
    "\n",
    "def plot_forecast_results(results_df, title=\"Forecast vs Actual\"):\n",
    "    \"\"\"\n",
    "    Plots actual vs. predicted values along with RMSE, MAPE, and Max Error.\n",
    "\n",
    "    Parameters:\n",
    "    - results_df (pd.DataFrame): DataFrame with columns [\"y_true\", \"y_pred\"] and a datetime index\n",
    "    - title (str): Plot title\n",
    "\n",
    "    Returns:\n",
    "    - tuple: (RMSE, MAPE, Max Error) as floats\n",
    "    \"\"\"\n",
    "\n",
    "    y_true = results_df[\"y_true\"]\n",
    "    y_pred = results_df[\"y_pred\"]\n",
    "\n",
    "    # Calculate error metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    max_error = np.max(np.abs(y_true - y_pred))\n",
    "\n",
    "    # Create plot\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(results_df.index, y_true, label=\"Actual\", marker='o', linestyle='--', color='black')\n",
    "    plt.plot(results_df.index, y_pred, label=f\"Predicted RMSE={rmse:.1f}, MAPE={mape:.2f}%, Max Err={max_error:.1f}\",\n",
    "             marker='o', color='tab:green')\n",
    "    \n",
    "    # Annotate forecast errors above or below the points\n",
    "    for i in range(len(results_df)):\n",
    "        date = results_df.index[i]\n",
    "        actual = y_true[i]\n",
    "        predicted = y_pred[i]\n",
    "        diff = actual - predicted\n",
    "        plt.text(date, max(actual, predicted) + 1000, f\"{diff:+.1f}\", color='red', fontsize=12,\n",
    "                 ha='center', va='bottom' if diff > 0 else 'top')\n",
    "\n",
    "    # Axis and plot settings\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Household Deposits (NZDm)\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return rmse, mape, max_error\n",
    "\n",
    "def run_residual_boosting_pipeline(raw_df, target='household_deposits', use_cols=[], lags=[], rolling_windows=[], test_size=12, window_length=160, h=2, sp=12, n_estimators=200, learning_rate=0.01, max_depth=4, min_samples_leaf = 1, subsample = 1):\n",
    "\n",
    "    \"\"\"\n",
    "    End-to-end pipeline for evaluating the Residual Boosting Forecasting model\n",
    "    using AutoETS as base model and GradientBoosting for residual correction.\n",
    "\n",
    "    Parameters:\n",
    "    - raw_df (pd.DataFrame): Raw input DataFrame containing 'date', target, and predictors\n",
    "    - target (str): Target variable name\n",
    "    - use_cols (list): Features to use based on the SHAP feature selection\n",
    "    - lags (list): Lags to use based on the SHAP feature selection\n",
    "    - rolling_windows (list): Rolling window sizes for rolling features\n",
    "    - test_size (int): Number of months to reserve for test set (must be >= h)\n",
    "    - window_length (int): Number of past points used in GBT residual correction\n",
    "    - h (int): Forecast horizon (e.g. 2 = 2-month ahead, from the data perpsective)\n",
    "    - sp (int): Seasonal period (set to 12 for the deposits data as strong yearly seasonaility observed)\n",
    "    - n_estimators, learning_rate, max_depth, min_samples_leaf, subsample: parameters for GBT\n",
    "\n",
    "    Returns:\n",
    "    - plots the actual versus prediction (plot not returned)\n",
    "    - tuple: (RMSE, MAPE, Max Error) from forecast evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    # Data preparation\n",
    "    df = prepare_features(raw_df, target, lags, rolling_windows, use_cols)\n",
    "\n",
    "    # Train-test split\n",
    "    y_train, y_test = temporal_train_test_split(df, test_size=test_size)\n",
    "\n",
    "    # Build forecasting pipeline\n",
    "    forecaster = build_forecaster(sp, n_estimators, learning_rate, max_depth, window_length, min_samples_leaf, subsample)\n",
    "\n",
    "    # Define expanding CV\n",
    "    splitter = ExpandingWindowSplitter(\n",
    "        initial_window=len(y_train) - h + 1,\n",
    "        step_length=1,\n",
    "        fh=[h]\n",
    "    )\n",
    "\n",
    "    # Evaluate with cross-validation\n",
    "    cv_results = evaluate(\n",
    "        forecaster=forecaster,\n",
    "        y=df[target],\n",
    "        X=df.drop(columns=[target]),\n",
    "        cv=splitter,\n",
    "        strategy=\"refit\",\n",
    "        return_data=True,\n",
    "    )\n",
    "\n",
    "    # Extract predictions\n",
    "    results = pd.DataFrame({\n",
    "        \"y_true\": [s.values[0] for s in cv_results[\"y_test\"]],\n",
    "        \"y_pred\": [s.values[0] for s in cv_results[\"y_pred\"]]\n",
    "    })\n",
    "    results.index = y_test.index\n",
    "    results.index = results.index.to_timestamp()\n",
    "\n",
    "    # Plot results\n",
    "    return plot_forecast_results(results, title=\"AutoETS + Residual Boosting Forecast\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e13d8b5-2941-40d2-87e2-ffe8935c5183",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Read Data\n",
    "raw_df = pd.read_csv('../data/processed/combined_total_household_data_interpolate.csv')\n",
    "raw_df = raw_df.sort_values('date')\n",
    "\n",
    "# Read config\n",
    "with open(\"model_configs.json\", \"r\") as f:\n",
    "    param_dict = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab4695b3-eac0-4a4b-9b7b-67933c4b2987",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Evaluation for 2-Month Horizon Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d14b87e7-af0f-409c-896c-cfcc9c1cfda7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# initialisation\n",
    "h = 2\n",
    "test_size = 12\n",
    "horizon_params = param_dict[f'model_forecast_h{h}']\n",
    "predictors = horizon_params['predictors']\n",
    "target = 'household_deposits'\n",
    "\n",
    "# evaluation for 2-month horizon\n",
    "rmse, mape, max_error = run_residual_boosting_pipeline(\n",
    "    raw_df=raw_df[['date',target]+predictors],\n",
    "    use_cols=horizon_params['best_features'],\n",
    "    lags=horizon_params['best_lags'],\n",
    "    rolling_windows=horizon_params['best_rolling_windows'],\n",
    "    test_size=test_size,\n",
    "    window_length=horizon_params['window_length'],\n",
    "    h=h,\n",
    "    sp=horizon_params['sp'],\n",
    "    n_estimators=horizon_params['n_estimators'],\n",
    "    learning_rate=horizon_params['learning_rate'],\n",
    "    max_depth=horizon_params['max_depth'],\n",
    "    min_samples_leaf = horizon_params['min_samples_leaf'],\n",
    "    subsample = horizon_params['subsample']\n",
    ")\n",
    "\n",
    "print(f\"Evaluation Results for Horizon {h}\")\n",
    "print(f\"RMSE: {round(rmse,2)}\")\n",
    "print(f\"MAPE: {round(mape,2)}%\")\n",
    "print(f\"Max Error: {round(max_error, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04a03772-9ebd-404e-b6d0-c7209a52b1d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Evaluation for 5-Month Horizon Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abad83e6-6658-45be-8b31-85dd39bdfcc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# initialisation\n",
    "h = 5\n",
    "test_size = 12\n",
    "horizon_params = param_dict[f'model_forecast_h{h}']\n",
    "predictors = horizon_params['predictors']\n",
    "target = 'household_deposits'\n",
    "\n",
    "#  evaluation for 5-month horizon \n",
    "rmse, mape, max_error = run_residual_boosting_pipeline(\n",
    "    raw_df=raw_df[['date',target]+predictors],\n",
    "    use_cols=horizon_params['best_features'],\n",
    "    lags=horizon_params['best_lags'],\n",
    "    rolling_windows=horizon_params['best_rolling_windows'],\n",
    "    test_size=test_size,\n",
    "    window_length=horizon_params['window_length'],\n",
    "    h=h,\n",
    "    sp=12,#horizon_params['sp'],\n",
    "    n_estimators=horizon_params['n_estimators'],\n",
    "    learning_rate=horizon_params['learning_rate'],\n",
    "    max_depth=horizon_params['max_depth'],\n",
    "    min_samples_leaf = horizon_params['min_samples_leaf'],\n",
    "    subsample = horizon_params['subsample']\n",
    ")\n",
    "\n",
    "print(f\"Evaluation Results for Horizon {h}\")\n",
    "print(f\"RMSE: {round(rmse,2)}\")\n",
    "print(f\"MAPE: {round(mape,2)}%\")\n",
    "print(f\"Max Error: {round(max_error, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e0ed503-2b59-4407-82ae-d1ed29b34ad1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Evaluation for 8-Month Horizon Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b2529ec-f9e4-4710-9f58-c66ff65545c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# initialisation\n",
    "h = 8\n",
    "test_size = 12\n",
    "horizon_params = param_dict[f'model_forecast_h{h}']\n",
    "predictors = horizon_params['predictors']\n",
    "target = 'household_deposits'\n",
    "\n",
    "#  evaluation for 8-month horizon\n",
    "rmse, mape, max_error = run_residual_boosting_pipeline(\n",
    "    raw_df=raw_df[['date',target]+predictors],\n",
    "    use_cols=horizon_params['best_features'],\n",
    "    lags=horizon_params['best_lags'],\n",
    "    rolling_windows=horizon_params['best_rolling_windows'],\n",
    "    test_size=test_size,\n",
    "    window_length=horizon_params['window_length'],\n",
    "    h=h,\n",
    "    sp=12,#horizon_params['sp'],\n",
    "    n_estimators=horizon_params['n_estimators'],\n",
    "    learning_rate=horizon_params['learning_rate'],\n",
    "    max_depth=horizon_params['max_depth'],\n",
    "    min_samples_leaf = horizon_params['min_samples_leaf'],\n",
    "    subsample = horizon_params['subsample']\n",
    ")\n",
    "\n",
    "print(f\"Evaluation Results for Horizon {h}\")\n",
    "print(f\"RMSE: {round(rmse,2)}\")\n",
    "print(f\"MAPE: {round(mape,2)}%\")\n",
    "print(f\"Max Error: {round(max_error, 2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37aad09c-a640-46a1-a956-1618680e76a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Evaluation for 14-Month Horizon Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "837919c2-70b0-4463-9bba-184048455de9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# initialisation\n",
    "h = 14\n",
    "test_size = 12\n",
    "horizon_params = param_dict[f'model_forecast_h{h}']\n",
    "predictors = horizon_params['predictors']\n",
    "target = 'household_deposits'\n",
    "\n",
    "#  evaluation for 14-month horizon\n",
    "rmse, mape, max_error = run_residual_boosting_pipeline(\n",
    "    raw_df=raw_df[['date',target]+predictors],\n",
    "    use_cols=horizon_params['best_features'],\n",
    "    lags=horizon_params['best_lags'],\n",
    "    rolling_windows=horizon_params['best_rolling_windows'],\n",
    "    test_size=test_size,\n",
    "    window_length=horizon_params['window_length'],\n",
    "    h=h,\n",
    "    sp=12,\n",
    "    n_estimators=horizon_params['n_estimators'],\n",
    "    learning_rate=horizon_params['learning_rate'],\n",
    "    max_depth=horizon_params['max_depth'],\n",
    "    min_samples_leaf = horizon_params['min_samples_leaf'],\n",
    "    subsample = horizon_params['subsample']\n",
    ")\n",
    "\n",
    "print(f\"Evaluation Results for Horizon {h}\")\n",
    "print(f\"RMSE: {round(rmse,2)}\")\n",
    "print(f\"MAPE: {round(mape,2)}%\")\n",
    "print(f\"Max Error: {round(max_error, 2)}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_model_evaluation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
