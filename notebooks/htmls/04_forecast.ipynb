{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "607782f3-0cf3-435d-bf7e-45edba97ca55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e9c2583-823a-4ce5-8a54-a292dd099290",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sktime.split import temporal_train_test_split\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.performance_metrics.forecasting import mean_absolute_percentage_error, mean_squared_error\n",
    "from sktime.forecasting.residual_booster import ResidualBoostingForecaster\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sktime.forecasting.compose import make_reduction\n",
    "from sktime.forecasting.ets import AutoETS\n",
    "from sktime.forecasting.compose import TransformedTargetForecaster\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Set seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8076a8a3-6c6e-45bc-882e-a005ca9c0de5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Forecast for Total Household Deposits\n",
    "\n",
    "This notebook generates future forecasts for total household deposits at the 2, 5, 8, and 14-month horizons using the most recent available data. \n",
    "\n",
    "Additionally, a bonus 1-month-ahead forecast is produced by leveraging the 2-month model with one data point held back â€” effectively generating a 2-month forecast from an earlier point in time (e.g., predicting September from July instead of August - latest data). This approach accounts for real-world data lags and provides an estimate for months where official data may not yet be available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b541a30-e08e-4132-89f2-407762cbf848",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_features(df, target_col, predictor_cols, lags=[1,3,4, 6,12], rolling_windows=[3,4, 6,12]):\n",
    "    \"\"\"\n",
    "    Creates lag-based and rolling statistical features for both the target and predictor columns.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame with 'date', target, and predictor columns\n",
    "    - target_col (str): Name of the target column\n",
    "    - predictor_cols (list): List of predictor column names\n",
    "    - lags (list): Lags to apply for lag, diff, and pct change features\n",
    "    - rolling_windows (list): Window sizes for rolling statistics (mean, std, min, max)\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with engineered features and datetime features (year, month, quarter)\n",
    "    \"\"\"\n",
    "    # Ensure date is in datetime format\n",
    "    df = df.copy()\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values('date')\n",
    "    df.set_index('date', inplace=True)\n",
    "\n",
    "    new_features = {}\n",
    "\n",
    "    # For each predictor (and target), compute lags, rolling stats, etc.\n",
    "    for col in [target_col] + predictor_cols:\n",
    "        # Lag features\n",
    "        for lag in lags:\n",
    "            new_features[f'{col}_lag{lag}'] = df[col].shift(lag) # lag\n",
    "\n",
    "        # Differences and pct changes\n",
    "        for lag in lags:\n",
    "            new_features[f'{col}_diff{lag}'] = df[col].diff(lag) # difference\n",
    "            if (df[col] != 0).all():\n",
    "                new_features[f'{col}_roc{lag}'] = df[col].pct_change(lag) # rate of change\n",
    "\n",
    "        # Rolling stats\n",
    "        for win in rolling_windows:\n",
    "            new_features[f'{col}_ma{win}'] = df[col].rolling(win).mean()\n",
    "            new_features[f'{col}_std{win}'] = df[col].rolling(win).std()\n",
    "            new_features[f'{col}_min{win}'] = df[col].rolling(win).min()\n",
    "            new_features[f'{col}_max{win}'] = df[col].rolling(win).max()\n",
    "\n",
    "    # Combine original and new features        \n",
    "    df_new = pd.concat([df]+ [pd.DataFrame(new_features, index=df.index)], axis=1)\n",
    "\n",
    "    # Add datetime features\n",
    "    df_new['year'] = df_new.index.year\n",
    "    df_new['month'] = df_new.index.month\n",
    "    df_new['quarter'] = df_new.index.quarter\n",
    "\n",
    "    # Drop rows with missing values caused by shifting/rolling\n",
    "    df_new = df_new.dropna()\n",
    "    df_new.reset_index(inplace=True)\n",
    "\n",
    "    return df_new\n",
    "\n",
    "def prepare_features(df, target, lags, rolling_windows, use_cols):\n",
    "    \"\"\"\n",
    "    Wrapper around create_features to:\n",
    "    - Generate features\n",
    "    - Subset to required columns\n",
    "    - Set proper monthly period index\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame with 'date', target and predictors\n",
    "    - target (str): Target column name\n",
    "    - lags (list): List of lag values\n",
    "    - rolling_windows (list): List of rolling window sizes\n",
    "    - use_cols (list): Final features to retain\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Processed and indexed DataFrame ready for forecasting\n",
    "    \"\"\"\n",
    "\n",
    "    predictor_cols = [x for x in df.columns if x not in ['date', target]]\n",
    "    df = create_features(df, target, predictor_cols, lags=lags, rolling_windows=rolling_windows)\n",
    "    df = df[['date', target] + use_cols].copy()\n",
    "    df = df.set_index('date').asfreq('MS')  # Set frequency to monthly start\n",
    "    df.index = df.index.to_period(\"M\")  # Use PeriodIndex (monthly) as required for sktime\n",
    "    return df\n",
    "\n",
    "def build_forecaster(sp, n_estimators, learning_rate, max_depth, window_length, min_samples_leaf, subsample):\n",
    "    \"\"\"\n",
    "    Builds the combined forecasting model (AutoETS + Gradient Boosting residual corrector).\n",
    "\n",
    "    Parameters:\n",
    "    - sp (int): Seasonal period (e.g. 12 for monthly data with yearly seasonality)\n",
    "    - n_estimators (int): Number of boosting trees\n",
    "    - learning_rate (float): Learning rate for GBT\n",
    "    - max_depth (int): Max tree depth\n",
    "    - window_length (int): Number of past time points used in the residual booster\n",
    "    - min_samples_leaf (int): Minimum samples in leaf node\n",
    "    - subsample (float): Fraction of samples used in boosting\n",
    "     \n",
    "    Returns:\n",
    "    - sktime.forecasting.compose._pipeline.ForecasterPipeline: A composite forecaster object\n",
    "    \"\"\"\n",
    "    base_forecaster = AutoETS(auto=True, sp=sp, n_jobs=-1)\n",
    "\n",
    "    regressor = GradientBoostingRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_leaf = min_samples_leaf, \n",
    "        subsample = subsample, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    residual_model = make_reduction(regressor, window_length=window_length, strategy=\"direct\")\n",
    "    residual_forecaster = TransformedTargetForecaster([\n",
    "        (\"scaler\", MinMaxScaler()),\n",
    "        (\"regressor\", residual_model)\n",
    "    ])\n",
    "\n",
    "    full_forecaster = ResidualBoostingForecaster(base_forecaster, residual_forecaster)\n",
    "    return full_forecaster\n",
    "\n",
    "def forecast_future(raw_df, target='household_deposits', use_cols=[], lags=[], rolling_windows=[], forecast_horizon=12, sp=12, n_estimators=200, learning_rate=0.01, max_depth=4, min_samples_leaf=1, subsample=1, window_length=160):\n",
    "    \"\"\"\n",
    "    Fits the time series model for the specified horizon on the full data and predicts h steps ahead.\n",
    "\n",
    "    Parameters:\n",
    "    - raw_df (pd.DataFrame): Raw input DataFrame with 'date', target and predictors\n",
    "    - target (str): Target variable to forecast\n",
    "    - use_cols (list): Features to use based on the SHAP feature selection\n",
    "    - lags (list): Lags to use based on the SHAP feature selection\n",
    "    - rolling_windows (list): Rolling window sizes for features\n",
    "    - forecast_horizon (int): Number of months ahead to forecast (e.g. 2 = 2-month ahead, from the data perpsective)\n",
    "    - sp (int): Seasonal period (set to 12 for the deposits data as strong yearly seasonaility observed)\n",
    "    - n_estimators, learning_rate, max_depth, min_samples_leaf, subsample: parameters for GBT\n",
    "    - window_length (int): Number of past observations used in GBT residual correction\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with forecasted value at future date index\n",
    "    \"\"\"\n",
    "\n",
    "    # Genereate and prepare features\n",
    "    df = prepare_features(raw_df, target, lags, rolling_windows, use_cols)\n",
    "\n",
    "    # Fit full model on all data\n",
    "    forecaster = build_forecaster(sp, n_estimators, learning_rate, max_depth, window_length, min_samples_leaf, subsample)\n",
    "    y = df[target]\n",
    "    X = df.drop(columns=[target])\n",
    "    forecaster.fit(y, X, fh = [forecast_horizon])\n",
    "\n",
    "    # Forecast h steps ahead\n",
    "    y_pred = forecaster.predict(fh=[forecast_horizon], X=X)\n",
    "\n",
    "    # Compute the forecast date\n",
    "    forecast_date = (df.index[-1] + forecast_horizon).to_timestamp()\n",
    "\n",
    "    forecast_df = pd.DataFrame({\n",
    "        \"forecast\": [y_pred.values[0]]\n",
    "    }, index=[forecast_date])\n",
    "\n",
    "    return forecast_df\n",
    "\n",
    "def get_forecast_params(h, param_dict, raw_df):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    - parameters for model\n",
    "    - adjusted raw_df (e.g. shortened if using earlier point for horizon 1)\n",
    "    - actual forecast horizon to use (2 for horizon 1, otherwise the original)\n",
    "    \"\"\"\n",
    "    if h == 1:\n",
    "        params = param_dict[f'model_forecast_h2']  # Use same model as horizon 2\n",
    "        df = raw_df[:-1].copy()        # Drop latest to simulate previous month\n",
    "        actual_h = 2            # Still forecasting 2 months ahead\n",
    "    else:\n",
    "        params = param_dict[f'model_forecast_h{h}']\n",
    "        df = raw_df.copy()\n",
    "        actual_h = h\n",
    "    return params, df, actual_h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a732297b-4a1c-40c3-a9ca-c495cb039865",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Read Data\n",
    "raw_df = pd.read_csv('../data/processed/combined_total_household_data_interpolate.csv')\n",
    "raw_df = raw_df.sort_values('date')\n",
    "\n",
    "# Read config\n",
    "with open(\"model_configs.json\", \"r\") as f:\n",
    "    param_dict = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c1f32e9-a98d-4df8-a4d2-f3664c4a03af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize empty list to collect forecast DataFrames\n",
    "all_forecasts = []\n",
    "horizons = [1,2,5,8,14] \n",
    "target = 'household_deposits'\n",
    "\n",
    "# Loop through each horizon\n",
    "for h in horizons:\n",
    "    print(f\"Forecasting horizon: {h} month(s) ahead\")\n",
    "\n",
    "    # Get model params, data, and adjusted forecast horizon\n",
    "    params, df_subset, actual_h = get_forecast_params(h, param_dict, raw_df)\n",
    "\n",
    "    # Prepare DataFrame with required columns\n",
    "    predictors = params['predictors']\n",
    "    df_subset = df_subset[['date', target] + predictors].copy()\n",
    "\n",
    "    # Generate the forecast\n",
    "    forecast_df = forecast_future(\n",
    "        raw_df=df_subset,\n",
    "        target=target,\n",
    "        use_cols=params['best_features'],\n",
    "        lags=params['best_lags'],\n",
    "        rolling_windows=params['best_rolling_windows'],\n",
    "        forecast_horizon=actual_h,\n",
    "        sp=params['sp'],\n",
    "        n_estimators=params['n_estimators'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        max_depth=params['max_depth'],\n",
    "        min_samples_leaf=params['min_samples_leaf'],\n",
    "        subsample=params['subsample'],\n",
    "        window_length=params['window_length']\n",
    "    )\n",
    "\n",
    "    # Label the forecast by the intended horizon (not the underlying `fh`)\n",
    "    forecast_df[\"horizon\"] = h\n",
    "    all_forecasts.append(forecast_df)\n",
    "\n",
    "# Combine all forecasts\n",
    "final_forecast_df = pd.concat(all_forecasts).sort_index()\n",
    "final_forecast_df\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_forecast",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
