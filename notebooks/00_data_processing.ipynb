{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bb6b595-f64d-435b-9658-50ef9d28c5de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6be9b872-7f8d-4636-9d8f-4791147a2ee7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9002a47-c714-465d-bfd2-5bb1bcadbd50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Total NZ Household Deposits\n",
    "\n",
    "The code below cleans the raw input data and converts it into the correct format. It processes the quarterly data by using duplication and interpolation which are joined and saved separately. See datalog for detail on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a7c412d-ab29-4572-8cc1-27f004c55cf2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_quarterlies_duplicate(df):\n",
    "    # List to hold monthly duplicated rows\n",
    "    monthly_rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        # Use the quarter-end date from the original row\n",
    "        quarter_end = pd.to_datetime(row['date'])\n",
    "\n",
    "        # Generate 3 monthly dates ending at the quarter-end (i.e., previous two months + current)\n",
    "        months = pd.date_range(end=quarter_end, periods=3, freq='M')\n",
    "\n",
    "        # Duplicate the row for each month in the quarter\n",
    "        for m in months:\n",
    "            new_row = row.copy()\n",
    "            new_row['date'] = m\n",
    "            monthly_rows.append(new_row)\n",
    "\n",
    "    # Create new DataFrame with monthly frequency\n",
    "    monthly_df = pd.DataFrame(monthly_rows)\n",
    "\n",
    "    # Format 'date' column to 'YYYY-MM'\n",
    "    monthly_df['date'] = pd.to_datetime(monthly_df['date']).dt.strftime('%Y-%m')\n",
    "\n",
    "    return monthly_df\n",
    "\n",
    "\n",
    "def process_quarterlies_interpolate(df):\n",
    "    non_date_cols = [x for x in df.columns if x != 'date']\n",
    "    \n",
    "    # Create a complete monthly date range\n",
    "    months = pd.date_range(start=df.date.min(), end=df.date.max(), freq='MS')\n",
    "    month_df = pd.DataFrame(months, columns=['date'])\n",
    "    month_df['date'] = month_df['date'].dt.strftime('%Y-%m')\n",
    "\n",
    "    # Merge with original DataFrame\n",
    "    month_df = month_df.merge(df, on='date', how='left')\n",
    "\n",
    "    # Interpolate with direction both ways\n",
    "    month_df[non_date_cols] = month_df[non_date_cols].interpolate(limit_direction='both')\n",
    "\n",
    "    return month_df\n",
    "\n",
    "\n",
    "def clean_and_process_df(df):\n",
    "    # Standardize column names\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "    df.columns = (\n",
    "        df.columns\n",
    "        .str.replace(r\"\\s*\\(.*?\\)\", \"\", regex=True)   # remove text in parentheses\n",
    "        .str.replace(\" \", \"_\", regex=False)           # replace spaces with underscores\n",
    "        .str.replace(\"-\", \"_\", regex=False)           # replace hyphens with underscores\n",
    "        .str.replace(\".\", \"\", regex=False)            # remove dots\n",
    "        .str.replace(\"\\t\", \"\", regex=False)            # remove tabs\n",
    "    )\n",
    "\n",
    "    # Convert 'date' column to datetime and format\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime(df['date'], dayfirst=True, errors='coerce').dt.strftime('%Y-%m')\n",
    "\n",
    "    # Drop rows where all elements are NaN\n",
    "    df = df.dropna(how='all')\n",
    "\n",
    "    # Convert applicable columns to numeric\n",
    "    for col in df.columns:\n",
    "        if col == 'date':\n",
    "            continue\n",
    "        if df[col].dtype == object:\n",
    "            # Remove commas if present\n",
    "            if df[col].astype(str).str.contains(\",\", na=False).any():\n",
    "                df[col] = df[col].str.replace(\",\", \"\", regex=False)\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0323eb4-6a4d-4e66-8014-2a808fe9acb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# read raw input\n",
    "monthly_df = pd.read_csv('../data/raw/total_household_deposits_monthly_data.csv')\n",
    "quarterly_df = pd.read_csv('../data/raw/total_household_deposits_quarterly_data.csv')\n",
    "\n",
    "# clean and process df\n",
    "monthly_df = clean_and_process_df(monthly_df)\n",
    "quarterly_df = clean_and_process_df(quarterly_df)\n",
    "\n",
    "# process quarterly data\n",
    "duplicate_quarterly_df = process_quarterlies_duplicate(quarterly_df) # duplicate quarterly data\n",
    "interpolated_quarterly_df = process_quarterlies_interpolate(quarterly_df) # interpolate quarterly data\n",
    "\n",
    "# combine and save\n",
    "combined_data_duplicated = monthly_df.merge(duplicate_quarterly_df, on = 'date', how = 'left').sort_values(by='date')\n",
    "combined_data_interpolated = monthly_df.merge(interpolated_quarterly_df, on = 'date', how = 'left').sort_values(by='date')\n",
    "\n",
    "combined_data_duplicated.to_csv('../data/processed/combined_total_household_data_duplicate.csv', index = False)\n",
    "combined_data_interpolated.to_csv('../data/processed/combined_total_household_data_interpolate.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df062393-5e14-4ff6-8eb7-48c55c86c488",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sense check if there are gaps or dates missing\n",
    "\n",
    "def check_missing_dates_plot(df):\n",
    "    # Drop rows that contain any NaNs\n",
    "    df_cleaned = df.dropna()\n",
    "\n",
    "    # List of dates that have no missing values across any column\n",
    "    complete_dates = list(df_cleaned.date)\n",
    "\n",
    "    # Create a DataFrame to flag missing dates\n",
    "    date_check_df = df[['date']].copy()\n",
    "    date_check_df['missing'] = date_check_df['date'].apply(lambda x: 1 if x in complete_dates else 0)\n",
    "\n",
    "    # Set date as datetime index for plotting\n",
    "    date_check_df['date'] = pd.to_datetime(date_check_df['date'])\n",
    "    date_check_df = date_check_df.set_index('date')\n",
    "\n",
    "    # Plot the presence of data (1 = complete row, 0 = row with any NaN)\n",
    "    date_check_df.plot.line(figsize=(15, 5), title='Presence of Complete Data by Date (0 = missing)')\n",
    "\n",
    "    return date_check_df\n",
    "  \n",
    "print('Sense check if any dates are missing')\n",
    "#check_missing_dates_plot(combined_data_duplicated)\n",
    "check_missing_dates_plot(combined_data_interpolated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32a01151-ff70-4584-aa9d-811581848391",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## write to catalogue\n",
    "#spark.createDataFrame(combined_data_interpolated).write.mode('overwrite').option('overwriteSchema','true').saveAsTable('deposits_forecasting.default.total_hshld_deposits_input_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8bfe71db-120d-465d-95b9-61ba4341c83c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "00_data_processing",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
