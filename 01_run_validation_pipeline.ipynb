{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba458013-dbee-4460-9918-a509712ceb80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49015e6b-9713-43ce-bb6d-3469f1019bf0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da809c87-ad95-4017-bced-6c984a221173",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from src.ingest_data import load_and_prepare_data\n",
    "from src.evaluate_model import evaluate_models_on_test\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Set seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "111d8b63-7ed0-49af-8bff-518903b5d7d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CONFIG_PATH = Path(\"configs/\")\n",
    "\n",
    "def run_all_models_evaluation():\n",
    "    all_forecasts = []\n",
    "    for config_file in CONFIG_PATH.glob(\"*.json\"):\n",
    "\n",
    "        # Skip evaluation of horizon 1 since it is technically 2-month horizon forecast\n",
    "        if config_file.name.endswith('_h1.json'):\n",
    "            print(f\"Skipping config {config_file.name} (horizon 1)\")\n",
    "            continue\n",
    "\n",
    "        with open(config_file) as f:\n",
    "            params = json.load(f)\n",
    "\n",
    "        model_name = params[\"model_name\"]\n",
    "        target = params['target']\n",
    "        horizon = params['horizon']\n",
    "\n",
    "        print(f\"Running pipeline for: {model_name}\")\n",
    "\n",
    "        # Load and prepare data\n",
    "        df = load_and_prepare_data(\n",
    "            path=\"data/processed/combined_total_household_data_interpolate.csv\",\n",
    "            target=target,\n",
    "            params=params\n",
    "        )\n",
    "\n",
    "        # Define output path per model + horizon for plot & CSV saving\n",
    "        output_path = Path(f\"outputs/validations/{model_name}\")\n",
    "\n",
    "        # Train the model and evaluate\n",
    "        rmse, mape, max_error, results = evaluate_models_on_test(df, h=horizon, param_dict=params, target = target, output_path = output_path)\n",
    "\n",
    "        # Collect summary info for this run\n",
    "        all_forecasts.append({\n",
    "            \"model_name\": model_name,\n",
    "            \"target\": target,\n",
    "            \"horizon\": horizon,\n",
    "            \"rmse\": rmse,\n",
    "            \"mape\": mape,\n",
    "            \"max_error\": max_error\n",
    "        })\n",
    "\n",
    "    # Combine all forecast summaries and save\n",
    "    summary_df = pd.DataFrame(all_forecasts)\n",
    "    summary_path = Path(\"outputs/validations/all_forecasts_summary.csv\")\n",
    "    summary_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "    print(f\"Saved all forecasts summary to: {summary_path}\")\n",
    "\n",
    "    return summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7beaa27d-dc30-45b3-9a9a-f6f526d8abbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "summary_df = run_all_models_evaluation()\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "091f3875-a2da-4228-a221-b1db5fabbb2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_run_validation_pipeline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
